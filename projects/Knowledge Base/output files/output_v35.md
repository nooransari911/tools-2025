{
  "structured_list": [
    {
      "file": "./backend/.env",
      "content": "# Backend .env file\n# Copy and rename this to .env and fill in your values\n\n# --- Gemini API Keys and Model Names ---\n# These should ideally match the keys used by your original script\n# Ensure these environment variables are accessible to the FastAPI process\n\n# PAID Tier API Key (Required if using 'paid' api_key_type)\nAPI_KEY_PAID=\"YOUR_GOOGLE_AI_STUDIO_API_KEY_PAID\"\n\n# FREE Tier API Key (Required if using 'free' api_key_type, e.g., for experimental models)\n# API_KEY_FREE=\"YOUR_GOOGLE_AI_STUDIO_API_KEY_FREE\"\n\n# Model Names (Make sure these match Google's naming conventions)\nGEMINI_20_PRO=\"gemini-1.5-pro-latest\"\nGEMINI_20_PRO_EXP=\"models/gemini-1.5-pro-exp-001\" # Example experimental name, adjust if needed\nGEMINI_20_FL=\"gemini-1.5-flash-latest\"\n\n# --- System Instruction Paths (Relative to Knowledge Base/src) ---\n# These point to files *within* the original script's structure\n# The backend will need access to the 'Knowledge Base' directory\nSYSTEM_INSTRUCTIONS_PATH=\"./data/system_instructions_text.txt\"\nSYSTEM_INSTRUCTIONS_STRUCTURED_PATH=\"./data/system_instructions_structured.txt\"\n\n# --- Logging ---\nLOG_FILE=\"./logs/backend_app.log\"\nLOG_LEVEL=\"INFO\"\n\n# --- CORS Origins (Optional, for frontend development) ---\n# List of allowed origins, comma-separated (e.g., http://localhost:3000,https://yourdomain.com)\n# Use \"*\" to allow all, but be cautious in production.\nALLOWED_ORIGINS=\"http://localhost:3000\"\n"
    },
    {
      "file": "./backend/requirements.txt",
      "content": "fastapi>=0.110.0\nuvicorn[standard]>=0.29.0\npython-dotenv>=1.0.0\nrequests>=2.31.0 # Often useful, though not directly used yet\naiofiles>=23.2.1 # For async file operations if needed later\npython-multipart>=0.0.9 # For file uploads\ngoogle-generativeai>=0.5.4 # Match version used by original script if possible\npydantic>=2.0.0 # Match version used by original script if possible\n\n# Add any other dependencies needed by your backend or the imported 'Knowledge Base' code\n# Ensure versions are compatible with the 'Knowledge Base' script's dependencies\n"
    },
    {
      "file": "./backend/app/__init__.py",
      "content": "# Makes 'app' directory a Python package"
    },
    {
      "file": "./backend/app/config.py",
      "content": "import os\nimport logging\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom typing import List, Optional\n\n# Determine the base directory of the backend application\n# This assumes config.py is in backend/app/\nBACKEND_DIR = Path(__file__).resolve().parent.parent\n# Go up one level to get the root of the webapp project (AI_doc_processor_webapp)\nWEBAPP_ROOT_DIR = BACKEND_DIR.parent\n# Go up one more level to the directory containing both webapp and knowledge base\nPROJECT_ROOT_DIR = WEBAPP_ROOT_DIR.parent\n# Define the path to the Knowledge Base directory\nKNOWLEDGE_BASE_DIR = PROJECT_ROOT_DIR / \"Knowledge Base\" # Adjust if your actual name differs\n\n# Load environment variables from .env file located in the backend directory\ndotenv_path = BACKEND_DIR / '.env'\nload_dotenv(dotenv_path=dotenv_path)\n\n# --- Logging Configuration ---\nLOG_FILE = Path(os.getenv(\"LOG_FILE\", str(BACKEND_DIR / \"logs\" / \"backend_app.log\")))\nLOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n\n# Ensure log directory exists\nLOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n\nlogging.basicConfig(\n    level=getattr(logging, LOG_LEVEL, logging.INFO),\n    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n    handlers=[\n        logging.StreamHandler(), # Log to console\n        logging.FileHandler(LOG_FILE) # Log to file\n    ]\n)\nlogger = logging.getLogger(__name__)\nlogger.info(f\"Logging configured. Level: {LOG_LEVEL}, File: {LOG_FILE}\")\n\n# --- CORS Configuration ---\nALLOWED_ORIGINS_STR = os.getenv(\"ALLOWED_ORIGINS\", \"\")\nALLOWED_ORIGINS: List[str] = [origin.strip() for origin in ALLOWED_ORIGINS_STR.split(',') if origin.strip()]\nif not ALLOWED_ORIGINS:\n    logger.warning(\"ALLOWED_ORIGINS not set in .env, CORS might block frontend requests.\")\nelse:\n    logger.info(f\"CORS Allowed Origins: {ALLOWED_ORIGINS}\")\n\n# --- Knowledge Base Path ---\n# Check if the Knowledge Base directory exists\nif not KNOWLEDGE_BASE_DIR.is_dir():\n    logger.error(f\"Critical: Knowledge Base directory not found at expected path: {KNOWLEDGE_BASE_DIR}\")\n    logger.error(\"Ensure the 'Knowledge Base' directory is correctly placed relative to the 'backend' directory and the name matches.\")\n    # Depending on setup, you might want to raise an exception here\n    # raise FileNotFoundError(f\"Knowledge Base directory not found: {KNOWLEDGE_BASE_DIR}\")\nelse:\n    logger.info(f\"Knowledge Base directory found: {KNOWLEDGE_BASE_DIR}\")\n\n# --- Function to add Knowledge Base to sys.path ---\ndef add_knowledge_base_to_path():\n    import sys\n    # Path to the 'src' directory within the Knowledge Base\n    kb_src_path = str(KNOWLEDGE_BASE_DIR)\n    if kb_src_path not in sys.path:\n        sys.path.insert(0, kb_src_path) # Add Knowledge Base root to allow 'import src'\n        logger.info(f\"Added Knowledge Base root to sys.path: {kb_src_path}\")\n    # Also add the src directory directly if needed (depends on how imports are done in KB)\n    # kb_src_itself = str(KNOWLEDGE_BASE_DIR / 'src')\n    # if kb_src_itself not in sys.path:\n    #     sys.path.insert(0, kb_src_itself)\n    #     logger.info(f\"Added Knowledge Base src to sys.path: {kb_src_itself}\")\n\n# --- Temporary File Storage ---\n# Define a directory for temporary uploads within the backend\nTEMP_UPLOAD_DIR = BACKEND_DIR / \"temp_uploads\"\nTEMP_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\nlogger.info(f\"Temporary upload directory: {TEMP_UPLOAD_DIR}\")\n\n# --- API Key Type Determination (Assumption) ---\n# For now, we hardcode the API key type. This could be made configurable.\n# If you want the frontend to choose, you'll need to modify the frontend and backend.\nDEFAULT_API_KEY_TYPE = \"paid\" # Or \"free\"\nlogger.warning(f\"Using hardcoded API Key Type: '{DEFAULT_API_KEY_TYPE}'. Update config.py if this needs to change.\")\n\n# --- Access Environment Variables (Example) ---\n# You can access other env vars directly using os.getenv()\n# Example: paid_api_key = os.getenv(\"API_KEY_PAID\")\n"
    },
    {
      "file": "./backend/app/models.py",
      "content": "from pydantic import BaseModel, Field\nfrom typing import Optional, List, Dict, Any\n\n# --- Pydantic Models for API Request/Response --- #\n\nclass UsageMetadata(BaseModel):\n    \"\"\"Mirrors the structure expected from gemini_utils for usage metadata.\"\"\"\n    prompt_token_count: Optional[int] = None\n    candidates_token_count: Optional[int] = None\n    total_token_count: Optional[int] = None\n\nclass ProcessResponse(BaseModel):\n    \"\"\"Response structure for the /process endpoint.\"\"\"\n    status: str = Field(..., description=\"'success' or 'error'\")\n    raw_output: Optional[str] = Field(None, description=\"The raw text output from the Gemini model.\")\n    # structured_output can be Any valid JSON structure (dict, list, etc.)\n    structured_output: Optional[Any] = Field(None, description=\"The parsed JSON output if a schema was used and parsing succeeded.\")\n    schema_used: Optional[str] = Field(None, description=\"Name of the schema requested/used, or indication if none.\")\n    usage_metadata: Optional[UsageMetadata] = Field(None, description=\"Token usage statistics if available.\")\n    error_message: Optional[str] = Field(None, description=\"Details about the error if status is 'error'.\")\n\nclass SchemasResponse(BaseModel):\n    \"\"\"Response structure for the /schemas endpoint.\"\"\"\n    schemas: List[str] = Field(..., description=\"List of available schema names.\")\n"
    },
    {
      "file": "./backend/app/services.py",
      "content": "import os\nimport sys\nimport logging\nimport tempfile\nimport pathlib\nimport shutil\nfrom typing import Dict, Any, Optional, Tuple\n\n# Add Knowledge Base to sys.path *before* importing from it\nfrom .config import add_knowledge_base_to_path, KNOWLEDGE_BASE_DIR, TEMP_UPLOAD_DIR, DEFAULT_API_KEY_TYPE\nadd_knowledge_base_to_path()\n\n# Now import from Knowledge Base\ntry:\n    # Assuming gemini_utils is in Knowledge Base/src/utils/\n    from src.utils import gemini_utils\n    from google.genai import types as genai_types # Import types for type hints\n    from google.api_core import exceptions as google_exceptions\n    logger = logging.getLogger(__name__)\n    logger.info(\"Successfully imported gemini_utils and google types.\")\nexcept ImportError as e:\n    logging.critical(f\"Failed to import from Knowledge Base src: {e}\", exc_info=True)\n    logging.critical(\"Ensure the 'Knowledge Base' directory is correctly structured and accessible.\")\n    # Optionally raise the error to prevent app startup\n    raise\nexcept Exception as e:\n    logging.critical(f\"An unexpected error occurred during import: {e}\", exc_info=True)\n    raise\n\ndef get_available_schemas() -> list[str]:\n    \"\"\"Retrieves the list of registered schema names from gemini_utils.\"\"\"\n    try:\n        # Ensure schemas are loaded (gemini_utils might load them upon import)\n        # If schemas are loaded dynamically, add logic here\n        schema_names = list(gemini_utils.SCHEMA_REGISTRY.keys())\n        logger.info(f\"Found available schemas: {schema_names}\")\n        # Ensure the default schema is listed if it exists\n        if gemini_utils.DEFAULT_SCHEMA_NAME not in schema_names and gemini_utils.DEFAULT_SCHEMA_NAME in gemini_utils.SCHEMA_REGISTRY:\n            schema_names.insert(0, gemini_utils.DEFAULT_SCHEMA_NAME) # Add default if missing\n        return schema_names\n    except Exception as e:\n        logger.error(f\"Error retrieving schemas: {e}\", exc_info=True)\n        return []\n\ndef process_single_document(file_path: pathlib.Path, prompt: str, model_type: str, schema_name: Optional[str]) -> Dict[str, Any]:\n    \"\"\"\n    Processes a single document using the refactored logic from gemini_utils.\n    Handles client configuration, content generation, and result parsing.\n    Returns a dictionary compatible with the ProcessResponse model.\n    \"\"\"\n    logger.info(f\"Starting processing for file: {file_path.name}, schema: {schema_name}, model: {model_type}\")\n    result = {\n        \"status\": \"error\",\n        \"raw_output\": None,\n        \"structured_output\": None,\n        \"schema_used\": schema_name if schema_name else \"(No Schema - Plain Text)\",\n        \"usage_metadata\": None,\n        \"error_message\": \"Processing failed.\"\n    }\n\n    try:\n        # 1. Determine API Key Type (Using hardcoded default for now)\n        api_key_type = DEFAULT_API_KEY_TYPE\n\n        # 2. Configure Gemini Client\n        # This function now raises ValueError on config issues (key/model name missing)\n        client, model_name_used = gemini_utils.configure_gemini(model_type, api_key_type)\n        logger.info(f\"Gemini client configured for model: {model_name_used}\")\n\n        # 3. Determine Mode and Resolve Schema\n        is_structured_mode = bool(schema_name)\n        schema_class = None\n        if is_structured_mode:\n            # Pass the schema name explicitly to the resolver\n            schema_class = gemini_utils.resolve_schema_class(schema_name)\n            if schema_class:\n                result[\"schema_used\"] = schema_class.__name__ # Update with resolved name\n                logger.info(f\"Resolved schema class: {schema_class.__name__}\")\n            else:\n                # Should not happen if default exists, but good practice to check\n                logger.warning(f\"Schema '{schema_name}' requested but could not resolve (even to default). Proceeding without structure.\")\n                is_structured_mode = False\n                result[\"schema_used\"] = \"(Requested schema not found)\"\n        else:\n            logger.info(\"No schema requested, running in plain text mode.\")\n\n        # 4. Load System Instructions\n        # Set cwd temporarily for relative paths in gemini_utils if needed\n        original_cwd = os.getcwd()\n        kb_src_dir = KNOWLEDGE_BASE_DIR / 'src'\n        try:\n            # gemini_utils loads instructions relative to env var paths,\n            # which might assume execution from Knowledge Base root.\n            # If SYSTEM_INSTRUCTIONS paths in .env are relative (e.g., './data/...'),\n            # changing CWD might be necessary.\n            # Let's assume absolute paths or paths relative to KB root work for now.\n            # os.chdir(KNOWLEDGE_BASE_DIR)\n            sys_instructions = gemini_utils.load_system_instructions(is_structured_mode)\n            logger.debug(f\"Loaded system instructions (structured={is_structured_mode})\")\n        finally:\n            os.chdir(original_cwd) # Change back CWD\n\n        # 5. Prepare Generation Config\n        gen_config_args = {\"system_instruction\": sys_instructions, \"max_output_tokens\": 8192}\n        if is_structured_mode and schema_class:\n            gen_config_args[\"response_mime_type\"] = \"application/json\"\n            gen_config_args[\"response_schema\"] = schema_class\n\n        # Ensure we use google.generativeai.types.GenerationConfig\n        generation_config = genai_types.GenerationConfig(**gen_config_args)\n        logger.debug(\"Generation config prepared.\")\n\n        # 6. Prepare Contents (Load file)\n        # Determine MIME type based on file extension\n        mime_type = None\n        suffix = file_path.suffix.lower()\n        if suffix == '.pdf':\n            mime_type = 'application/pdf'\n        elif suffix in ['.txt', '.md', '.json', '.html', '.py', '.js', '.css']: # Add other text types\n            mime_type = 'text/plain'\n        elif suffix in ['.jpeg', '.jpg', '.png', '.webp', '.gif']:\n             mime_map = {'.jpeg': 'image/jpeg', '.jpg': 'image/jpeg', '.png': 'image/png', '.webp': 'image/webp', '.gif': 'image/gif'}\n             mime_type = mime_map.get(suffix)\n        # Add more MIME types as needed\n\n        if mime_type:\n            logger.info(f\"Reading file {file_path.name} with MIME type {mime_type}\")\n            file_part = genai_types.Part.from_bytes(\n                mime_type=mime_type,\n                data=file_path.read_bytes()\n            )\n            contents = [file_part, prompt]\n        else:\n            logger.warning(f\"Unsupported file type: {suffix}. Trying to read as text.\")\n            try:\n                text_content = file_path.read_text(encoding='utf-8')\n                contents = [text_content, prompt]\n            except Exception as read_err:\n                logger.error(f\"Could not read file {file_path.name} as text: {read_err}\")\n                raise ValueError(f\"Unsupported file type ({suffix}) and failed to read as text.\") from read_err\n\n        logger.debug(f\"Contents prepared for API call (prompt length: {len(prompt)} chars).\")\n\n        # 7. Call Gemini API (Synchronous)\n        logger.info(\"Sending request to Gemini API...\")\n        response = gemini_utils.generate_gemini_content(\n            genai_client=client,\n            model_name=model_name_used,\n            contents=contents,\n            generation_config=generation_config,\n            is_structured_mode=is_structured_mode # Pass mode info\n        )\n        logger.info(\"Received response from Gemini API.\")\n\n        # 8. Process Response\n        result[\"raw_output\"] = response.text\n\n        if response.usage_metadata:\n            result[\"usage_metadata\"] = {\n                \"prompt_token_count\": response.usage_metadata.prompt_token_count,\n                \"candidates_token_count\": response.usage_metadata.candidates_token_count,\n                \"total_token_count\": response.usage_metadata.total_token_count\n            }\n            logger.info(f\"Usage: {result['usage_metadata']}\")\n\n        # Try parsing JSON if structured mode was intended\n        if is_structured_mode:\n            logger.info(\"Attempting to parse structured output (JSON)...\")\n            parsed_json = gemini_utils.parse_json_from_response_text(response.text)\n            if parsed_json is not None:\n                result[\"structured_output\"] = parsed_json\n                logger.info(\"Successfully parsed JSON from response.\")\n            else:\n                logger.warning(\"Structured mode requested, but failed to parse JSON from response text.\")\n                # Keep raw_output, structured_output remains None\n\n        result[\"status\"] = \"success\"\n        result[\"error_message\"] = None # Clear error message on success\n        logger.info(f\"Processing successful for file: {file_path.name}\")\n\n    except ValueError as ve:\n        logger.error(f\"Configuration or Value Error: {ve}\", exc_info=True)\n        result[\"error_message\"] = f\"Configuration Error: {ve}\"\n    except google_exceptions.GoogleAPIError as api_err:\n        logger.error(f\"Gemini API Error: {api_err}\", exc_info=True)\n        result[\"error_message\"] = f\"Gemini API Error: {api_err.message if hasattr(api_err, 'message') else api_err}\"\n    except ImportError as imp_err:\n         logger.critical(f\"Import Error during processing (likely KB path issue): {imp_err}\", exc_info=True)\n         result[\"error_message\"] = f\"Internal Server Error: Could not load necessary components. Check logs.\"\n    except Exception as e:\n        logger.error(f\"Unexpected error during processing: {e}\", exc_info=True)\n        result[\"error_message\"] = f\"An unexpected server error occurred: {e}\"\n\n    return result\n\ndef save_uploaded_file(file: Any) -> pathlib.Path:\n    \"\"\"Saves an uploaded file (FastAPI UploadFile) to a temporary location.\"\"\"\n    try:\n        # Create a temporary file with the original suffix\n        suffix = pathlib.Path(file.filename).suffix\n        # We use mkstemp for security and atomicity\n        fd, temp_path_str = tempfile.mkstemp(suffix=suffix, dir=TEMP_UPLOAD_DIR)\n        temp_path = pathlib.Path(temp_path_str)\n\n        logger.info(f\"Saving uploaded file '{file.filename}' to temporary path: {temp_path}\")\n        with os.fdopen(fd, \"wb\") as temp_file:\n            # Use shutil.copyfileobj for efficient copying\n            shutil.copyfileobj(file.file, temp_file)\n\n        return temp_path\n    except Exception as e:\n        logger.error(f\"Failed to save uploaded file {file.filename}: {e}\", exc_info=True)\n        raise IOError(f\"Could not save uploaded file: {e}\") from e\n    finally:\n        # Ensure the file object associated with UploadFile is closed\n        if hasattr(file, 'file') and hasattr(file.file, 'close'):\n            file.file.close()\n\ndef cleanup_temp_file(file_path: pathlib.Path):\n    \"\"\"Deletes a temporary file if it exists.\"\"\"\n    try:\n        if file_path and file_path.exists() and file_path.is_file():\n            file_path.unlink()\n            logger.info(f\"Cleaned up temporary file: {file_path}\")\n        else:\n            logger.warning(f\"Attempted to clean up non-existent file: {file_path}\")\n    except Exception as e:\n        logger.error(f\"Error cleaning up temporary file {file_path}: {e}\", exc_info=True)\n"
    },
    {
      "file": "./backend/app/main.py",
      "content": "import logging\nimport time\nfrom pathlib import Path\n\nfrom fastapi import FastAPI, File, UploadFile, Form, HTTPException, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\n\n# Import configurations, models, and services\nfrom . import config\nfrom .models import ProcessResponse, SchemasResponse\nfrom .services import (get_available_schemas, \n                       process_single_document, \n                       save_uploaded_file, \n                       cleanup_temp_file)\n\n# Initialize Logging\nlogger = logging.getLogger(__name__)\n\n# Create FastAPI app instance\napp = FastAPI(\n    title=\"AI Document Processor API\",\n    description=\"API backend for the AI Document Processor web application, interacting with Gemini.\",\n    version=\"0.1.0\"\n)\n\n# --- CORS Middleware --- #\n# Allows the frontend (running on a different port/domain) to communicate with the backend.\nif config.ALLOWED_ORIGINS:\n    app.add_middleware(\n        CORSM
