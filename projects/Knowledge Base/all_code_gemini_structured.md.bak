===== ./data/generic_JSON_response_schema.py =====
import enum
import types
from src.utils.gemini_utils import register_schema
from pydantic import BaseModel, RootModel, Field, model_validator
from typing import Optional, List, Dict, Any, Union, Type # Ensure Type is imported


# --- Ensure schema_config and register_schema are defined as before ---
# from schema_config import register_schema, DEFAULT_SCHEMA_NAME

# --- Enum defining common Python type names (as strings) ---
# (Same as before)
class PythonBasicTypeName(str, enum.Enum):
    STR = "str"
    INT = "int"
    FLOAT = "float"
    BOOL = "bool"
    LIST_STR = "list_str"
    DICT_STR_ITEMS = "dict_str_items"
    DICT_INT_ITEMS = "dict_int_items"
    NONE = "None"



PYTHON_TYPE_MAP: Dict[PythonBasicTypeName, Type] = {
    PythonBasicTypeName.STR: str,
    PythonBasicTypeName.INT: int,
    PythonBasicTypeName.FLOAT: float,
    PythonBasicTypeName.BOOL: bool,
    PythonBasicTypeName.LIST_STR: list, # Base type is list
    PythonBasicTypeName.DICT_STR_ITEMS: list, # Base type is list (of key-value items)
    PythonBasicTypeName.DICT_INT_ITEMS: list, # Base type is list (of key-value items)
    PythonBasicTypeName.NONE: types.NoneType,
}



class KeyValuePairStrStr (BaseModel):
    key: str = Field (..., description="Key for key-value pair")
    value: str = Field (..., description="Value (str) for the key-value pair")


class KeyValuePairStrInt (BaseModel):
    key: str = Field (..., description="Key for key-value pair")
    value: int = Field (..., description="Value (int) for the key-value pair")






# --- Define the structure for each item in the list ---
class ListDataItem(BaseModel):
    """
    Represents a single data item within a list, designed for maximum schema
    compatibility by avoiding Union/Any in field types. Exactly one '..._content'
    field should be non-None, matching the 'type' field (unless type is NONE).
    """
    # --- Mandatory Type Indicator ---
    type: PythonBasicTypeName = Field(
        ...,
        description="Indicates which specific content field holds the actual data for this item."
    )

    # --- Optional Content Fields (One per Type) ---
    # Basic Types
    string_content: Optional[str] = Field(None, description="Content if type is 'str'.")
    integer_content: Optional[int] = Field(None, description="Content if type is 'int'.")
    float_content: Optional[float] = Field(None, description="Content if type is 'float'.")
    boolean_content: Optional[bool] = Field(None, description="Content if type is 'bool'.")

    # Collection Types (Using basic, common structures for schema compatibility)
    # Note: For lists/dicts containing complex objects, you might need nested models.
    list_str_content: Optional[List[str]] = Field(
        None,
        description="Content if type is 'list'. Assumes a list of string."
    )
    dict_str_content: Optional[KeyValuePairStrStr] = Field(
        None,
        description="Content if type is 'dict'. Assumes string keys and string values."
    )
    dict_int_content: Optional[KeyValuePairStrInt] = Field(
        None,
        description="Content if type is 'dict'. Assumes str keys and int values."
    )
    # Note: No specific content field is needed for type 'None'. Its presence is indicated
    # by type='None' and all other content fields being None.

    # --- Optional Metadata Fields ---
    description: Optional[str] = Field(
        None,
        description="Optional description or context."
    )
    source: Optional[str] = Field(
        None,
        description="Optional source information."
    )
    label: Optional[str] = Field(
        None,
        description="Optional label or key associated with this item."
    )

    @model_validator(mode='after')
    def check_correct_content_field_populated(self) -> 'ListDataItem':
        """
        Ensures exactly one content field is populated and matches the declared 'type',
        or none are populated if type is 'None'.
        """
        # Map the type enum to the corresponding content field name
        type_to_field_map: Dict[PythonBasicTypeName, Optional[str]] = {
            PythonBasicTypeName.STR: 'string_content',
            PythonBasicTypeName.INT: 'integer_content',
            PythonBasicTypeName.FLOAT: 'float_content',
            PythonBasicTypeName.BOOL: 'boolean_content',
            PythonBasicTypeName.LIST_STR: 'list_str_content',
            PythonBasicTypeName.DICT_INT_ITEMS: 'dict_int_content',
            PythonBasicTypeName.DICT_STR_ITEMS: 'dict_str_content',
            PythonBasicTypeName.NONE: None # None type has no dedicated content field
        }

        expected_field_name = type_to_field_map.get(self.type)

        populated_fields = []
        for field_name in type_to_field_map.values():
            # Check fields that are supposed to hold content
            if field_name is not None and getattr(self, field_name) is not None:
                 # Need special check for boolean_content == False, it *is* populated
                 if field_name == 'boolean_content' or getattr(self, field_name):
                     populated_fields.append(field_name)

        # --- Validation Logic ---
        if self.type == PythonBasicTypeName.NONE:
            # If type is None, NO content field should be populated
            if populated_fields:
                raise ValueError(
                    f"Type is '{self.type.value}', but unexpected content field(s) "
                    f"are populated: {populated_fields}"
                )
        else:
            # If type is NOT None, expected_field_name should be non-None
            if expected_field_name is None:
                 # This indicates an internal configuration error (Enum vs map mismatch)
                 raise ValueError(f"Internal error: No content field mapped for type '{self.type.value}'")

            # Exactly one content field must be populated
            if len(populated_fields) == 0:
                 raise ValueError(
                    f"Type is '{self.type.value}', but no corresponding content field "
                    f"('{expected_field_name}') is populated."
                 )
            if len(populated_fields) > 1:
                raise ValueError(
                    f"Type is '{self.type.value}', but multiple content fields are populated: "
                    f"{populated_fields}. Only '{expected_field_name}' should be populated."
                )
            # The single populated field must be the correct one
            if populated_fields[0] != expected_field_name:
                 raise ValueError(
                    f"Type is '{self.type.value}', which requires field '{expected_field_name}', "
                    f"but field '{populated_fields[0]}' was populated instead."
                )


            # --- SNIPPET TO ADD: Value Type Validation ---
            expected_python_type = PYTHON_TYPE_MAP.get(self.type)
            if expected_python_type is None:
                raise ValueError(f"Internal config error: No Python type mapping for '{self.type.value}'")

            actual_value = getattr(self, expected_field_name)

            type_match = False
            if expected_python_type is float and isinstance(actual_value, int):
                type_match = True
            elif expected_python_type is types.NoneType: # Should only happen if type is NONE, handled above, but safe check
                 type_match = (actual_value is None)
            elif isinstance(actual_value, expected_python_type):
                type_match = True

            if not type_match:
                raise ValueError(
                    f"Value Type Mismatch: Field '{expected_field_name}' is populated, "
                    f"but its value's Python type ('{type(actual_value).__name__}') "
                    f"does not match the expected type ('{expected_python_type.__name__}') "
                    f"implied by the declared item type '{self.type.value}'. "
                    f"Value: {repr(actual_value)}"
                )
            # --- END OF SNIPPET ---


        # If all checks pass
        return self








@register_schema
class StructuredListOutput (BaseModel):
    """
    Response Schema with a list of typed data items;
    Presents structured and typed data in a list form;
    """

    structured_list: List [ListDataItem] = Field (..., description="The primary output structured as a list of data items, each with a declared type, content, and optional metadata.")

    notes: Optional [str] = Field (..., description="Optional notes about the generated response")

    summary: Optional [str] = Field (..., description="Optional summary about response")






===== ./data/PDF_page_JSON_schema.py =====
# --- Add this class definition ---
from src.utils.gemini_utils import register_schema
from pydantic import BaseModel # Added for schema definition
from typing import Optional, List # Added for strong typing in schema


class PdfPageContent(BaseModel):
    """
    Represents the extracted content structure of a single PDF page,
    likely exported from a presentation slide.
    """
    page_number: int
    section: Optional[str]                       # e.g., Chapter number, broad topic
    title: Optional[str]                         # Main title text on the page/slide
    text_content: List[str]                      # List of distinct text blocks or paragraphs
    image_descriptions: List[str]                # List of descriptions for images found

@register_schema
class PdfDocument(BaseModel):
    """
    Represents the structured content extracted from multiple pages of a PDF document.
    """
    pages: List[PdfPageContent]   


===== ./src/utils/gemini_utils.py =====
import os, sys, json
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Union, Type # Ensure Type is imported

from google.genai import types
from google import genai

from multiprocessing import Manager



SCHEMA_REGISTRY: Dict [str, Type[BaseModel]] = {}
SCHEMA_ENV_VAR = "STRUCTURED_OUTPUT_JSON_SCHEMA"
# DEFAULT_SCHEMA_NAME = "LabelledDataMapValidated"
DEFAULT_SCHEMA_NAME = "StructuredListOutput"
SELECTED_SCHEMA_CLASS: Optional [Type[BaseModel]] = None
SYS_INS = ""
OUTPUT_JSON_PATH = "OUTPUT_JSON_PATH"
MODEL_NAME = "GEMINI_20_FL"
PRO_MODEL_NAME = "GEMINI_20_PRO"
PRO_MODEL_NAME_EXP = "GEMINI_20_PRO_EXP"
FLASH_MODEL_NAME = "GEMINI_20_FL"
API_KEY_PAID_STR = "API_KEY_PAID"
API_KEY_FREE_STR = "API_KEY_FREE"
IS_STRUCTURED_OP_MODE = False
manager = Manager ()
USAGE_METADATA = manager.list ()



# --- Helper Function for Formatting ---
def format_number(num: int) -> str:
    """Formats an integer with commas as thousands separators."""
    if num is None:
        return "N/A"
    try:
        return f"{int(num):,}"
    except (ValueError, TypeError):
        return str(num) # Fallback if not an integer


# --- Setting schema class for structured output mode ---
def resolve_and_set_schema_class():
    """
    Reads the schema name from the environment variable, looks it up in the
    registry, and sets the global SELECTED_SCHEMA_CLASS. Falls back to default.
    """
    global SELECTED_SCHEMA_CLASS # To modify the global variable

    # Ensure registry and default name are available
    if not SCHEMA_REGISTRY or DEFAULT_SCHEMA_NAME not in SCHEMA_REGISTRY:
         log_msg = f"Error: Schema registry empty or default schema '{DEFAULT_SCHEMA_NAME}' not found."
         # Use logger if available, otherwise print and exit
         try:
             logger.error(log_msg)
         except NameError:
             print(log_msg, file=sys.stderr)
         sys.exit(1) # Cannot proceed without a default

    default_class = SCHEMA_REGISTRY[DEFAULT_SCHEMA_NAME]
    chosen_class = default_class # Start with default
    schema_source = f"default ('{DEFAULT_SCHEMA_NAME}')" # For logging

    # Get schema name from environment variable
    env_schema_name = os.getenv(SCHEMA_ENV_VAR)

    if env_schema_name and env_schema_name.strip():
        env_schema_name = env_schema_name.strip()

        # Look up the class in the registry
        found_class = SCHEMA_REGISTRY.get(env_schema_name)
        if found_class:
            chosen_class = found_class
            schema_source = f"environment variable ('{env_schema_name}')"
        else:
            pass
    else:
        pass
        # chosen_class remains default_class

    SELECTED_SCHEMA_CLASS = chosen_class
    return SELECTED_SCHEMA_CLASS.__name__

    # Optional: Check if the selected class is actually a BaseModel
    if not issubclass(SELECTED_SCHEMA_CLASS, BaseModel):
        log_msg = f"Error: Resolved schema '{SELECTED_SCHEMA_CLASS.__name__}' is not a Pydantic BaseModel."
        try: logger.error(log_msg)
        except NameError: print(log_msg, file=sys.stderr)
        sys.exit(1)


def register_schema(cls: Type[BaseModel]):
    """Decorator to automatically register a schema class using its own name as the key."""
    # Ensure the input is actually a class derived from BaseModel
    if not isinstance(cls, type) or not issubclass(cls, BaseModel):
        raise TypeError(f"Object passed to register_schema must be a Pydantic BaseModel subclass, not {type(cls)}")

    schema_name = cls.__name__
    # print (f"Registering {cls.__name__}")
    if schema_name in SCHEMA_REGISTRY:
        # Use logger if available, otherwise print warning
        log_msg = f"Warning: Schema name '{schema_name}' already registered. Overwriting."
        try:
            # Check if logger is defined and configured
            if 'logger' in globals() and isinstance(logger, logging.Logger):
                logger.warning(log_msg)
            else:
                print(log_msg)
        except NameError: # logger might not be defined globally yet
            print(log_msg)

    SCHEMA_REGISTRY[schema_name] = cls
    # Optional print for debugging registration:
    # print(f"DEBUG: Registered schema '{schema_name}' -> {cls}")
    return cls


# --- File I/O operations ---
def load_output_file_version_json ():
    global OUTPUT_JSON_PATH
    output_json_path = os.environ.get (OUTPUT_JSON_PATH)
    try:
        with open(output_json_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return None

def save_output_file_version_json ():
    pass
    base_filename = save_output_file_version ()
    json_filename = f"{base_filename}.json"
    return json_filename

def save_output_file_version ():
    global OUTPUT_JSON_PATH
    output_json_path = os.environ.get (OUTPUT_JSON_PATH)
    old_data = load_output_file_version_json ()
    new_data = {}

    if not old_data:
        old_data = {
            "version": 0,
            "filename": "./output files/output response v0"
        }
    new_data ["version"]   = old_data ["version"]   +  1
    new_data ["filepath"]  = f"./output files/output response v{new_data ["version"]}"
    with open(output_json_path, 'w') as f:
        json.dump(
            obj=new_data, 
            fp=f, 
            indent=4
        )
    return new_data ["filepath"]

def reset_output_file_version ():
    global OUTPUT_JSON_PATH
    output_json_path = os.environ.get (OUTPUT_JSON_PATH)
    old_data = {
        "version": 0,
        "filename": "./output files/output response v0"
    }
    with open(output_json_path, 'w') as f:
        json.dump(old_data, f, indent=4)



def JSON_responses_parse_write (all_responses: List [str]):
    # --- Initialization ---
    parsed_objects_list = [] # To store successfully parsed Python objects
    other_items_list = []    # To store ALL other original items
    start_marker = "```json\n"
    end_marker = "\n```"

    print(f"Processing {len(all_responses)} input items...")

    # --- Main Processing Loop ---
    for i, original_item in enumerate(all_responses):
        was_parsed_successfully = False
        parsed_object = None
        processed_via_markers = False # Flag to indicate if marker logic was attempted

        try:
            # --- Check 1: Is it a usable string? ---
            if isinstance(original_item, str):
                stripped_item = original_item.strip()
                if stripped_item: # Proceed only if string is not empty after stripping

                    # --- Check 2: Attempt Marker-Based Parsing ---
                    start_index = original_item.find(start_marker)
                    if start_index != -1:
                        processed_via_markers = True # Marker logic path taken
                        json_start_pos = start_index + len(start_marker)
                        end_index = original_item.find(end_marker, json_start_pos)

                        if end_index != -1:
                            content_between_markers = original_item[json_start_pos:end_index].strip()
                            if content_between_markers:
                                try:
                                    parsed_object = json.loads(content_between_markers)
                                    was_parsed_successfully = True # SUCCESS via markers
                                    # print(f"Debug: Index {i}: Parsed successfully via markers.")
                                except json.JSONDecodeError as e:
                                    print(f"Info: Index {i}: Content between markers is invalid JSON ({e}).")
                                    # Keep was_parsed_successfully = False
                            else:
                                print(f"Info: Index {i}: Markers found, but content between them is empty.")
                                # Keep was_parsed_successfully = False
                        else:
                            print(f"Info: Index {i}: Start marker found, but no subsequent end marker.")
                            # Keep was_parsed_successfully = False

                    # --- Check 3: Attempt Raw Parsing (if not processed via markers) ---
                    # Only attempt raw parse if marker logic was NOT attempted (no start marker found)
                    if not processed_via_markers:
                        try:
                            parsed_object = json.loads(stripped_item)
                            was_parsed_successfully = True # SUCCESS via raw parse
                            # print(f"Debug: Index {i}: Parsed successfully via raw string.")
                        except json.JSONDecodeError:
                            # Failed raw parse, it's likely just text
                            # Optional: print(f"Info: Index {i}: Not raw JSON.")
                            pass # Keep was_parsed_successfully = False

            # --- If not a string or empty after strip, was_parsed_successfully remains False ---

        except Exception as e:
            # Catch any unexpected errors during the processing of THIS specific item
            print(f"Error: Index {i}: Unexpected error processing item: {e}")
            was_parsed_successfully = False # Ensure it goes to the 'other' list

        # --- Final Assignment: Preserve Everything ---
        if was_parsed_successfully:
            parsed_objects_list.append(parsed_object)
        else:
            # Add the ORIGINAL item to the 'other' list if it wasn't parsed
            # This includes non-strings, empty strings, parse failures, and errors
            other_items_list.append(original_item)


    print(f"\nProcessing complete.")
    print(f"- Parsed {len(parsed_objects_list)} items as JSON.")
    print(f"- Collected {len(other_items_list)} other items.")
    # Verification: The counts should sum to the original number of items
    total_processed = len(parsed_objects_list) + len(other_items_list)
    print(f"- Total items accounted for: {total_processed} (Original: {len(all_responses)})")
    if total_processed != len(all_responses):
        print("!!! WARNING: Item count mismatch. Not all items were preserved.")


    # --- Write Parsed JSON Output File ---
    if parsed_objects_list:
        json_output_file_path = save_output_file_version_json ()
        print(f"\nWriting {len(parsed_objects_list)} parsed JSON objects to: {json_output_file_path}")
        try:
            with open(file=json_output_file_path, mode="w", encoding='utf-8') as f:
                json.dump(obj=parsed_objects_list, fp=f, indent=4)
            print(f"Successfully wrote JSON data to {json_output_file_path}.")
        except IOError as e:
            print(f"Error: Could not write JSON file '{json_output_file_path}'. Error: {e}")
        except Exception as e:
            print(f"Error: An unexpected error occurred during JSON file writing: {e}")
    else:
        print("\nNo valid JSON objects were parsed. JSON output file will not be created.")

    # --- Write Other Items Output File ---
    if other_items_list:
        other_output_file_path = "./output files/non-json output response.json"
        print(f"\nWriting {len(other_items_list)} other items to: {other_output_file_path}")
        try:
            with open(file=other_output_file_path, mode="w", encoding='utf-8') as f:
                for item in other_items_list:
                    # Write the string representation of the item + newline
                    f.write(str(item) + '\n')
            print(f"Successfully wrote other items to {other_output_file_path}.")
        except IOError as e:
            print(f"Error: Could not write other items file '{other_output_file_path}'. Error: {e}")
        except Exception as e:
            print(f"Error: An unexpected error occurred during other items file writing: {e}")
    else:
        print("\nNo 'other' items were collected. Other items output file will not be created.")




def normal_response_write(file_path: str, content: List[str]) -> bool:
    """
    Writes a list of strings to a specified file, one string per line.

    If the file extension is not '.md', it attempts to strip leading/trailing
    Markdown code block delimiters (```) from the content list.

    Handles directory creation if it doesn't exist and manages file
    operations safely using a context manager.

    Args:
        file_path: The full path to the target file (including extension).
        content: A list of strings to write to the file.

    Returns:
        True if the file was written successfully, False otherwise.
    """
    if not isinstance(content, list):
        print(f"Error: Content must be a list of strings. Got: {type(content)}", file=sys.stderr)
        return False
    # Optional stricter check:
    # if not all(isinstance(item, str) for item in content):
    #     print(f"Error: All items in the content list must be strings.", file=sys.stderr)
    #     return False

    # Make a copy if you need to preserve the original list outside the function
    # content_to_write = list(content) # Use content_to_write below instead of content
    # Or modify content directly if that's acceptable

    try:
        # --- SNIPPET START: Check extension and strip delimiters ---
        _, file_extension = os.path.splitext(file_path)

        if file_extension.lower() != '.md':

            # 3. Check if there are enough lines to potentially strip (at least 2)
            #    AND check if the first/last lines actually look like delimiters
            if len(content) >= 2 and \
               content[0].strip().startswith('```') and \
               content[-1].strip() == '```':

                # --- THIS IS THE ACTUAL STRIPPING STEP ---
                # Re-assign 'content' to the slice excluding the first and last lines.
                # This modifies which list the 'content' variable points to *within this function*.
                content = content[1:-1]
                # print(f"Debug: Stripped delimiters for {os.path.basename(file_path)}") # Optional debug prin
        # --- SNIPPET END ---

        # --- Safely handle the path ---
        dir_path = os.path.dirname(file_path)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)

        # --- Safely handle file writing ---
        with open(file_path, 'w', encoding='utf-8') as f:
            # --- Write the potentially modified content ---
            # Handle the edge case where stripping delimiters made the list empty
            if not content:
                 # Optionally write nothing, or maybe a placeholder?
                 # f.write("# Content stripped\n") # Example placeholder
                 pass # Writes an empty file in this case
            else:
                for line in content:
                    f.write(str(line) + '\n')

        return True

    except (IOError, OSError, TypeError, ValueError) as e:
        print(f"Error writing to file '{file_path}': {e}", file=sys.stderr)
        return False
    except Exception as e:
        print(f"An unexpected error occurred while writing to '{file_path}': {e}", file=sys.stderr)
        return False



def write_response_to_file (response_list: list):
    catch_all_file_path = f"{save_output_file_version ()}.md"


    if (len (sys.argv) >= 5) and (sys.argv [4] == "struct"):
        JSON_responses_parse_write (response_list)

    elif (len (sys.argv) >= 5):
        normal_response_write (sys.argv [4], response_list)

    else:
        print (f"written to {catch_all_file_path}")
        normal_response_write (catch_all_file_path, response_list)



# --- AI SDK Functions begin here ---
def load_prompt_string () -> str:
    prompt_file_path = sys.argv [3]

    # Validate prompt file
    if not os.path.isfile(prompt_file_path):
        print(f"No such file as {prompt_file_path}\n\n")
        sys.exit(1)

    # Load prompt file
    with open(prompt_file_path, "r") as prompt_file:
        prompt_file_string = prompt_file.read()
        prompt = prompt_file_string

    return prompt




def load_system_instructions():
    global SYS_INS, IS_STRUCTURED_OP_MODE
    # Retrieve the file path from the environment variable
    if IS_STRUCTURED_OP_MODE:
        instructions_file_path = os.getenv ('SYSTEM_INSTRUCTIONS_STRUCTURED_PATH')
    else:
        instructions_file_path = os.getenv ('SYSTEM_INSTRUCTIONS_PATH')

    if instructions_file_path:
        try:
            # Open and read the system instructions file
            with open(instructions_file_path, 'r') as file:
                SYS_INS = file.read()
            # print (SYS_INS)
            # print ("sys_ins L70: ", sys_ins, "\n")
        except Exception as e:
            print(f"Error reading system instructions file: {e}")
    else:
        print("Environment variable 'SYSTEM_INSTRUCTIONS_PATH' not set.")



def configure_genai():
    global SYS_INS, PRO_MODEL_NAME, FLASH_MODEL_NAME, API_KEY_PAID_STR, API_KEY_FREE_STR

    if len(sys.argv) < 3:
        raise ValueError("Model type (pro/flash) and API key type (free/paid) must be provided.")

    # SYS_INS = load_system_instructions ()
    # print (f"sys ins {SYS_INS}")
    model_type = sys.argv[1].lower()
    api_key_type = sys.argv[2].lower()

    if model_type == "pro":
        model_name = os.environ.get(PRO_MODEL_NAME)
    elif model_type == "flash":
        model_name = os.environ.get(FLASH_MODEL_NAME)
    else:
        raise ValueError("Invalid model_type. Must be 'pro' or 'flash'.")

    if api_key_type == "free":
        api_key = os.environ.get(API_KEY_FREE_STR)
        if model_type == "pro":
            model_name = os.environ.get(PRO_MODEL_NAME_EXP)
        if not api_key:
             raise ValueError(f"The {API_KEY_FREE_STR} environment variable is not set.")
    elif api_key_type == "paid":
        api_key = os.environ.get(API_KEY_PAID_STR)
        if not api_key:
            raise ValueError(f"The {API_KEY_PAID_STR} environment variable is not set.")
    else:
        raise ValueError("Invalid api_key_type. Must be 'free' or 'paid'.")

    client = genai.Client(api_key=api_key)
    return client, model_name




# --- The Core Function ---

def update_gemini_token_usage(usage_metadata_list: list[Any]) -> None:
    """
    Updates the total API token usage stored in a JSON file with human-readable output.

    Reads the current usage from a JSON file (determined by sys.argv[2]),
    calculates the new tokens used from the input list, adds them to the
    totals, and writes the updated totals back to the file. Prints usage
    numbers with thousands separators.

    Args:
        usage_metadata_list: A list of objects, where each object is expected
                             to have 'prompt_token_count' (input) and
                             'candidates_token_count' (output) attributes.
                             Typically GenerateContentResponseUsageMetadata objects.
    """
    # --- 1. Determine the target JSON file ---
    # Default filename
    filename = "./data/gemini_tokens_usage.json"
    usage_type = "Standard"

    # Check sys.argv for the 'free' argument
    # Ensure there are enough arguments before accessing sys.argv[2]
    if len(sys.argv) > 2 and sys.argv[2].lower() == "free":
        filename = "./data/gemini_tokens_usage_free.json"
        usage_type = "Free Tier"

    # print(f"--- Updating {usage_type} Usage ({filename}) ---")

    # --- 2. Read current usage from the file ---
    current_usage: Dict[str, int] = {"input_tokens": 0, "output_tokens": 0}
    try:
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                try:
                    content = f.read()
                    if content: # Check if file is not empty
                        current_usage = json.loads(content)
                        # Ensure keys exist, default to 0 if missing
                        if "input_tokens" not in current_usage:
                            current_usage["input_tokens"] = 0
                        if "output_tokens" not in current_usage:
                             current_usage["output_tokens"] = 0
                    else:
                        print(f"Warning: File '{filename}' was empty. Initializing usage.")
                except json.JSONDecodeError:
                    print(f"Error: Could not decode JSON from '{filename}'. Initializing usage.")
                    current_usage = {"input_tokens": 0, "output_tokens": 0} # Reset
        else:
             print(f"File '{filename}' not found. Creating and initializing usage.")

    except IOError as e:
        print(f"Error reading file '{filename}': {e}. Initializing usage.")
        current_usage = {"input_tokens": 0, "output_tokens": 0} # Reset

    # Use formatted printing for current usage
    # print(f"Current usage loaded: input={current_usage.get('input_tokens', 0):,}, output={current_usage.get('output_tokens', 0):,}")

    # --- 3. Calculate new tokens from the input list ---
    new_input_tokens = 0
    new_output_tokens = 0

    for usage_item in usage_metadata_list:
        # Check if attributes exist and are not None before adding
        if hasattr(usage_item, 'prompt_token_count') and usage_item.prompt_token_count is not None:
            new_input_tokens += usage_item.prompt_token_count
        else:
            print(f"Warning: Missing or None 'prompt_token_count' in item: {usage_item}")

        if hasattr(usage_item, 'candidates_token_count') and usage_item.candidates_token_count is not None:
            new_output_tokens += usage_item.candidates_token_count
        else:
             print(f"Warning: Missing or None 'candidates_token_count' in item: {usage_item}")

    # Use formatted printing for new tokens
    print(f"New usage:   input={new_input_tokens:,}, output={new_output_tokens:,}")

    # --- 4. Update total usage ---
    updated_usage = {
        "input_tokens": current_usage.get("input_tokens", 0) + new_input_tokens,
        "output_tokens": current_usage.get("output_tokens", 0) + new_output_tokens
    }

    # --- 5. Write updated usage back to the file ---
    try:
        with open(filename, 'w') as f:
            # Use indent for pretty printing in the file
            json.dump(updated_usage, f, indent=4)
        # print(f"Successfully updated '{filename}'.")
        # Use formatted printing for the final total usage
        print(f"Total usage: input={updated_usage['input_tokens']:,}, output={updated_usage['output_tokens']:,}")
    except IOError as e:
        print(f"Error writing updated usage to file '{filename}': {e}")

    # print("-" * (len(f"--- Updating {usage_type} Usage ({filename}) ---")))


===== ./gemini_generate new SDK.py =====
import sys
import os, json
import asyncio
import typing_extensions as typing
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Union, Type # Ensure Type is imported
import data.generic_JSON_response_schema
import data.PDF_page_JSON_schema
import src.utils.gemini_utils as gem_utils


import logging
import concurrent.futures
from multiprocessing import cpu_count, Manager
import argparse

# import google.generativeai as genai
from google.genai import types
from google import genai
import google
from dotenv import load_dotenv
import functools
import google.api_core
import pprint
import pathlib






load_dotenv()
# Set up logging with timestamp in the desired format (yyyy-mm-dd 24 hr)
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s : %(levelname)s : %(message)s",  # Default log format with timestamp, level, and message
    datefmt="%Y-%m-%d %H:%M:%S",  # Timestamp format (yyyy-mm-dd 24 hr)
    handlers=[logging.FileHandler("gemini.log")]  # Output logs to console
)
logger = logging.getLogger(__name__)



def log_entry_exit(func):
    """Decorator to log function entry and exit with function name."""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        func_logger = logging.getLogger(func.__module__)
        func_logger.debug(f"Entering {func.__name__}")
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            # Log function exit with function name
            func_logger.debug(f"Exiting {func.__name__}")
    return wrapper




@log_entry_exit
def gen_response(prompts, record):
    """Generate a response from the Gemini API using multiple prompts."""
    # print (f"{gem_utils.SYS_INS [:40]}")
    gemini_response = None
    RESPONSES = []
    client, model_name = gem_utils.configure_genai ()
    
    if not prompts:
        logger.error("No prompts provided.")
        raise Exception("No prompts provided")
    
    for prompt in prompts:
        # Append the prompt to the record for context
        record.append(prompt)
        if gemini_response:
            record.append(gemini_response.text)
        # logger.info (record)

        try:
            if gem_utils.IS_STRUCTURED_OP_MODE:
                gemini_response = client.models.generate_content(
                    model=model_name,
                    contents=record,
                    config=types.GenerateContentConfig(
                        system_instruction=gem_utils.SYS_INS,
                        max_output_tokens=65536,
                        response_mime_type="application/json",
                        response_schema = gem_utils.SELECTED_SCHEMA_CLASS
                    )
                )
                logger.info (gemini_response.usage_metadata)
                gem_utils.USAGE_METADATA.append (gemini_response.usage_metadata)
            else:
                gemini_response = client.models.generate_content(
                    model=model_name,
                    contents=record,
                    config=types.GenerateContentConfig(
                        system_instruction=gem_utils.SYS_INS,
                        max_output_tokens=65536
                    )
                )

                logger.info (gemini_response.usage_metadata)
                gem_utils.USAGE_METADATA.append (gemini_response.usage_metadata)


            # logger.info(f"Successfully generated response for prompt: {prompt}".rstrip())

        # except google.api_core.exceptions.ResourceExhausted as f:
        #     print("Error: API quota exhausted. Try again later.")
        #     return f"Error: {str(f)}"

        except Exception as e:
            # Log and handle errors appropriately
            logger.error(f"Error generating response for prompt '{prompt}': {e}")
            gemini_response = f"Error: {str(e)}"
            return f"Error: {str(e)}"

        record = []  # Reset the record for the next iteration
        # In this case, we do NOT reset the `record` here, because we need to keep context for subsequent prompts.

    return gemini_response.text

@log_entry_exit
def process_record(record, prompts, results_queue):
    """Process a single record with multiple prompts."""
    try:
        # Generate response based on record and prompts
        # print ("record L136:", [record])
        response = gen_response(prompts, [record])  # Pass record as list
        results_queue.put(response)  # Put the result in the queue
    except Exception as e:
        logger.error(f"Error processing record: {e}")
        results_queue.put(f"Error: {str(e)}")  # Put error message in the queue


@log_entry_exit
def collect_results_from_queue(results_queue):
    """Collect all results from the results_queue."""
    all_responses = []
    while not results_queue.empty():
        response = results_queue.get()
        all_responses.append(response)
    return all_responses


@log_entry_exit
def parallelize_processing(records, prompts):
    """Parallelize the processing of records and prompts using multiprocessing."""
    # global model
    # Get the number of available CPU cores
    num_workers = cpu_count()


    # Create a Manager and get a Queue that can be shared across processes
    with Manager() as manager:
        results_queue = manager.Queue()

        # Use ProcessPoolExecutor for parallel processing
        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for record in records:
                futures.append(executor.submit(process_record, record, prompts, results_queue))

            if not records:
                futures.append (executor.submit (process_record, "dummy text", prompts, results_queue))



            # Wait for all futures to complete
            concurrent.futures.wait(futures)
            # Collecting results from the queue as the workers complete
            all_responses = []
            for future in concurrent.futures.as_completed(futures):
                try:
                    # Ensure the process completes without error
                    future.result()  # If there was an exception in the worker, it will be raised here
                except Exception as e:
                    logger.error(f"Error during future processing: {e}")

            # Now gather all results from the queue
            all_responses = collect_results_from_queue(results_queue)

    return all_responses




@log_entry_exit
def files_content() -> list:
    """
    Reads files from a directory, handling text, markdown, and PDF files.
    Returns a list of file contents (strings for text/markdown, Blobs for PDFs).
    """
    md_directory = './files/'
    records = []

    try:
        for f in os.listdir(md_directory):
            file_path = os.path.join(md_directory, f)

            try:  # Inner try-except for individual file processing
                if f.endswith((".txt", ".md", ".json")):
                    with open(file_path, 'r', encoding="utf-8") as file:
                        records.append(file.read())
                elif f.endswith(".pdf"):
                    pathlib_file_path = pathlib.Path(file_path)
                    pdf_part = types.Part.from_bytes (
                        data=pathlib_file_path.read_bytes(),
                        mime_type='application/pdf'
                    )
                    records.append(pdf_part)
                elif f.endswith(".jpeg"):
                     pathlib_file_path = pathlib.Path(file_path)
                     jpeg_part = types.Part.from_bytes(
                         data=pathlib_file_path.read_bytes(),
                         mime_type='image/jpeg'
                     )
                     records.append(jpeg_part)
                else:
                    logger.warning(f"Skipping unsupported file type: {f}")

            except FileNotFoundError:
                logger.error(f"File not found: {file_path}")  # Specific file, not directory
                # Don't exit; continue processing other files
            except OSError as e:
                logger.error(f"OS error reading file {file_path}: {e}")
                # Don't exit; continue processing other files
            except (TypeError, ValueError) as e:
                logger.error(f"Error processing file content {file_path} : {e}")
            except Exception as e:
                logger.error(f"Unexpected error processing {file_path}: {e}")
                # Consider logging stack trace for debugging:
                # logger.exception(f"Unexpected error processing {file_path}: {e}")

        return records  # Return even if some files had errors

    except FileNotFoundError:
        logger.error(f"Directory not found: {md_directory}")
        sys.exit(1)  # Exit if the *directory* is not found
    except OSError as e:
        logger.error(f"OS error accessing directory {md_directory}: {e}")
        sys.exit(1) #exit if cannot access directory
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
        sys.exit(1)  # Exit for unexpected errors at the directory level


def lines_content ():
    # First argument is the file containing records (e.g., links)
    input_file = sys.argv[1]

    try:
        with open(input_file, 'r') as f:
            records = [line.strip() for line in f.readlines()]
            return records
    except FileNotFoundError:
        logger.error(f"File not found: {input_file}")
        sys.exit(1)



async def files_count_tokens_async () -> dict:
    """
    Reads files and "asynchronously" counts tokens (using asyncio.to_thread).
    ONLY uses asyncio.to_thread for count_tokens. File reading is synchronous
    Returns only the files_tokens dictionary.
    """
    
    md_directory = './files/'
    files_tokens = {}
    client, model_name = gem_utils.configure_genai() # Get client and model_name


    async def process_file(file_path):
        nonlocal files_tokens

        if file_path.endswith((".txt", ".md")):
            try:
                # Synchronous file reading:
                with open(file_path, 'r', encoding="utf-8") as f:
                    content = f.read()

                # "Asynchronous" token counting (using asyncio.to_thread):
                token_count = await asyncio.to_thread(client.models.count_tokens, model=model_name, contents=[content])
                files_tokens[file_path] = token_count.total_tokens


            except Exception as e:
                print(f"Error processing {file_path}: {e}", file=sys.stderr)
                files_tokens[file_path] = -1

        elif file_path.endswith(".pdf"):
            try:
                pathlib_file_path = pathlib.Path(file_path)
                content = pathlib_file_path.read_bytes()
                # Create Part directly
                pdf_part = types.Part.from_bytes(data=content, mime_type='application/pdf')
                # "Asynchronous" token counting (using asyncio.to_thread):
                # Note: contents expects a list
                token_count = await asyncio.to_thread(client.models.count_tokens, model=model_name, contents=[pdf_part])
                files_tokens[file_path] = token_count.total_tokens
            except Exception as e:
                print(f"Error processing {file_path}: {e}", file=sys.stderr)
                files_tokens[file_path] = -1
        elif file_path.endswith(".jpeg"):
            try:
                pathlib_file_path = pathlib.Path(file_path)
                content = pathlib_file_path.read_bytes()
                # Create Part directly
                jpeg_part = types.Part.from_bytes(data=content, mime_type='image/jpeg')
                # "Asynchronous" token counting (using asyncio.to_thread):
                # Note: contents expects a list
                token_count = await asyncio.to_thread(client.models.count_tokens, model=model_name, contents=[jpeg_part])
                files_tokens[file_path] = token_count.total_tokens
            except Exception as e:
                print(f"Error processing {file_path}: {e}", file=sys.stderr)
                files_tokens[file_path] = -1
        else:
            print(f"Skipping unsupported file type: {file_path}", file=sys.stderr)

    try:
        tasks = [process_file(os.path.join(md_directory, f)) for f in os.listdir(md_directory)]
        await asyncio.gather(*tasks)
        return files_tokens

    except FileNotFoundError:
        print(f"Error: Directory not found: {md_directory}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error: An unexpected error occurred: {e}", file=sys.stderr)
        sys.exit(1)




@log_entry_exit
def res_agg (base_responses):
    # perform aggregate on base_responses
    try:
        with open("base_prompts.md", "r") as file:
            base_prompt = file.readline().strip()  # Read the first line and remove any trailing whitespace
            agg_prompt  = file.readline().strip()  # Read the second line and remove any trailing whitespace

    except FileNotFoundError:
        print("Error: base_prompts.md not found.")
        base_prompt = ""  # If the file isn't found, set base_prompt to an empty string
        agg_prompt = ""  # If the file isn't found, set agg_prompt to an empty string

    except Exception as e:
        print(f"An error occurred: {e}")
    
    prompts = ""
    custom_agg = input("Enter your custom aggregation prompt if any: ").strip()  # Take user input and strip any extra spaces

    # Append only if custom_agg is not empty
    # Now base_prompt is redundant
    if custom_agg:
        prompts = f"{agg_prompt} {custom_agg}"
    else:
        prompts = f"{agg_prompt}"
    # Log the created prompt
    logger.info(f"Aggregate prompt <agg prompt>: {prompts}")
    base_responses.append (prompts)

    client, model_name = gem_utils.configure_genai() # Get client and model_name
    gemini_response = client.models.generate_content(
        model=model_name,
        contents=base_responses,
        config=types.GenerateContentConfig(
            system_instruction=gem_utils.SYS_INS
        ) # Pass system instruction via config
    )

    aggregate_responses = [gemini_response.text]
    return aggregate_responses


@log_entry_exit
async def main():
    """Main function to read input, parallelize the work, and print the results."""
    logger.critical ("A new run;")
    logger.critical ("<run>")
    gem_utils.resolve_and_set_schema_class ()
    gem_utils.load_system_instructions ()
    print (f"Resolved JSON Schema: {gem_utils.SELECTED_SCHEMA_CLASS}")
    # serializable_registry = {k: v.__name__ for k, v in gem_utils.SCHEMA_REGISTRY.items()}
    # print (f"Registry JSON Schema: {json.dumps (serializable_registry, indent=4)}")

    if (len (sys.argv) >= 5) and (sys.argv [4] == "struct"):
        gem_utils.IS_STRUCTURED_OP_MODE = True
    else:
        gem_utils.IS_STRUCTURED_OP_MODE = False


    records = []
    prompts = []

    prompt = gem_utils.load_prompt_string ()
    prompts.append(prompt)
    
    user_input = int (input ("Mode (1: Normal, 2: w/o files): "))
    agg_opt = input ("Do you want to perform aggregate operation? 1 for agg, 2 for no agg; ")

    if user_input == 1:
        records = files_content()
        try:
            if sys.argv[3].lower() == "count":
                token_count = await files_count_tokens_async()
                pprint.pprint(token_count, indent=4)
        except IndexError:
            pass

    # elif user_input == 3:
    #     records = lines_content()

    elif user_input == 2:
        pass

    else:
        logger.error(f"Invalid option chosen: {user_input}")
        sys.exit(1)    

    logger.info(f"Starting parallel processing for {len(records)} records with {len(prompts)} prompts.")

    all_responses = parallelize_processing(records, prompts)
    if (agg_opt == '1'):
        all_responses = res_agg (all_responses)
    else:
        pass
    gem_utils.write_response_to_file (all_responses)
    gem_utils.update_gemini_token_usage (gem_utils.USAGE_METADATA)
    logger.critical ("</run>")







    
if __name__ == "__main__":
    # trace_span = client.start_span(name="application_start")

    try:
        asyncio.run (main())

    except EOFError as eof:
        print ("^D: EOF event")
        sys.exit (0)
    except KeyboardInterrupt as kb_itr:
        print ("^C: Keyboard interrupt event")
        sys.exit (0)
    # trace_span.end ()



