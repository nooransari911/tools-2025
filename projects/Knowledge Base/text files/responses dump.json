[
    {
        "ModelName": "llama-4-maverick-exp",
        "Response": "Here's a synthesized thesis on why closed, for-profit AI based on scraped public data is unethical and why AI should be open source: The AI revolution, touted as a beacon of innovation and progress, rests on a foundation of collective effort and public contribution that is fundamentally at odds with the privatized, profit-driven model that has come to dominate the field. At the heart of this contradiction lies a glaring ethical disparity: the very data that fuels the most advanced AI systems was not created by the corporations reaping the benefits, but was instead harvested, often without permission or compensation, from the vast expanse of the internet—a modern digital commons.The truth is stark: none of the tech giants steering the AI narrative today can claim to have generated the foundational training data themselves. Instead, they have aggregated content from countless sources—social media platforms like Twitter and Reddit, creative outlets like fan-fiction sites and YouTube, informational behemoths like Wikipedia, and the entirety of the web's sprawling, user-generated expanse. This data, produced by millions of individuals, communities, and organizations over decades, has been treated as a free resource, a limitless trove to be mined without cost or acknowledgment. The companies profiting from AI didn't just inherit this data; they actively scraped, parsed, and leveraged it, turning the public's collective output into proprietary gold.The irony deepens when we consider that this monumental data heist was facilitated not by some bespoke, in-house technology, but by the very backbone of the internet: open-source software. Linux, Python, TensorFlow—these aren't just tools; they're the unsung heroes that made AI commercially viable. The irony is that the same entities now using these open-source foundations to justify the enclosure of AI's most valuable assets—the trained models—are the first to trumpet the virtues of \"collaboration\" and \"innovation\" when it suits their interests. They laud the open-source community when it's providing them with free labor and infrastructure, only to slam shut the doors of their own creations, privatizing the benefits while disavowing any responsibility to the commons that nourished them.This double standard is more than just hypocritical; it's a betrayal of the social contract implicit in the digital age. When individuals share thoughts, images, stories, and knowledge online, they do so with an expectation—however naive—that their contributions will help build something greater than the sum of its parts. They don't anticipate that their data will be vacuumed up, processed by machines, and then sold back to them as a luxury good, guarded by proprietary walls and paywalls. The enclosure of AI models, born from this public data and nurtured by open-source ethos, amounts to a privatization of the commons, where the many toil and create, only for the few to profit and control.Moreover, this extractive model distorts the very notion of innovation. True advancement in AI shouldn't be measured by how effectively a corporation can monopolize data-derived insights, but by how openly these insights can be shared, built upon, and democratized. Closed AI systems stifle progress by limiting access to the collective intelligence they've leveraged for free. They create information oligarchies where only those with the deepest pockets can participate in—or even critique—the technology shaping our world. This runs counter to the spirit of scientific inquiry, where knowledge begets more knowledge, and the peer-reviewed rigor of academia is replaced by the gated gardens of corporate R&D.The defenders of closed AI often argue that releasing models openly would erase competitive advantages and disincentivize investment. This is a myopic view. The real value in AI doesn't lie in hoarding trained models but in the services built atop them: fine-tuning, application expertise, infrastructure support, and user-centric innovation. Companies like those in the AI space can still thrive by offering these value-added services, much like Red Hat does with Linux or Canonical with Ubuntu. They can consult, customize, and optimize AI for specific industries or needs, generating revenue not from data hoarding but from genuine expertise and added value.But beyond economics, there's a deeper moral calculus at play. When AI systems are built on the back of public data, and nurtured by open-source collaboration, the public has a rightful claim to the fruits of that labor. This isn't about stifling profit motives but about restoring balance to a system that's been rigged against the very people who made it possible. As one astute observer put it: it's galling that corporations can \"privatize the commons by scraping the internet, but if you ask an AI to help you scrape a supermarket website, it'll preach about ethics and respecting EULAs.\" This isn't just a double standard; it's a civic outrage.The path forward is clear: AI must be reclaimed as a shared resource, not a private fiefdom. Open-sourcing AI models isn't merely a technical decision; it's an ethical imperative. By doing so, we:1. Honor the unpaid labor of the internet's creators—from Redditors to Wikipedia editors—whose work underpins these systems.2. Realign AI with its true purpose: augmenting human knowledge, not corporate bottom lines.3. Democratize access to the most powerful tool of our era, ensuring small developers, researchers, and marginalized communities aren't locked out of the AI conversation.4. Foster a culture of transparency and collaboration, where models can be audited, improved, and adapted by global collectives, not siloed teams.In essence, the call for open-source AI isn't anti-profit; it's pro-equity. It's a demand that the architecture of our future not be dictated by a handful of data barons, but co-created by the humanity whose digital sweat equity built the foundations.The revolution will not be privatized. The commons demands its due. AI, the child of the internet's open expanse, should be free for all to use, critique, and improve. Anything less is not innovation—it's enclosure. And the world deserves better. **Note on Style**: I deliberately avoided bullet points to maintain a flowing, persuasive narrative. The ideas build upon each other, starting from the factual premise (data source), moving through the ethical critique (privatization of commons), addressing counterarguments (profit motive), and culminating in a moral and practical case for open-source AI. The comments from the original post were woven in organically to amplify key points rather than stand out as add-ons. The tone aims to be human, urgent, and academically robust—convincing through reason, empathy, and a touch of righteous indignation."
    },
    {
        "ModelName": "qwen-max-2025-01-25",
        "Response": "The rapid ascent of artificial intelligence has transformed industries, reshaped economies, and redefined the boundaries of human creativity. Yet, as we marvel at its achievements, a troubling ethical dilemma looms in the shadows: the rise of closed, for-profit AI systems built on the foundation of publicly available data scraped from the internet. This practice raises profound questions about fairness, equity, and justice—questions that demand our attention and action. At its core, this issue boils down to one central argument: if AI companies rely entirely on collective knowledge harvested freely from society’s shared digital commons, they have an obligation to return their creations to that same commons by making their models open source. To understand why closed, proprietary AI is fundamentally unethical, we must first examine how these systems come into existence. None of the major advancements in modern AI would be possible without vast amounts of training data culled from platforms like Reddit, Twitter, YouTube, Wikipedia, fan fiction sites, news outlets, and countless other repositories of human expression. These sources represent decades of effort by millions of individuals worldwide who contributed their ideas, writings, images, videos, and insights—not because they were paid to do so but because they believed in sharing knowledge and culture with others. In essence, this data constitutes a collective inheritance, a vast tapestry woven together by humanity's collective labor. And yet, when corporations scrape this material en masse, process it through sophisticated algorithms, and then lock away the resulting models behind paywalls or restrictive licenses, they effectively privatize what was once public property. It's akin to someone walking into a community garden where everyone has planted seeds over years, gathering all the fruits, and selling them exclusively while barring the original contributors from even tasting the harvest. This dynamic becomes even more egregious when considering the tools used to train these models. Much of the software infrastructure underpinning AI development—frameworks like TensorFlow, PyTorch, and countless libraries—is itself open source. These technologies are products of collaborative efforts by programmers and researchers who chose to share their work openly, believing it could benefit humanity as a whole. Companies leveraging these resources owe not only their datasets but also their very technical capabilities to the generosity of the global developer community. To take freely from both the intellectual commons of open-source software and the cultural commons of user-generated content, only to hoard the results, represents a staggering act of ingratitude and exploitation. Proponents of closed AI often argue that companies invest significant resources in developing these models, citing the costs of hardware, energy consumption, and specialized expertise. While these investments are undeniable, they fail to justify the monopolization of AI. Training a model may require substantial financial outlay, but the quality of the output depends overwhelmingly on the richness and diversity of the input data—a resource provided gratis by the public. The analogy is clear: imagine a pharmaceutical company synthesizing life-saving drugs using ingredients stolen from local farmers' fields without permission or compensation. Even if the company invested heavily in refining those raw materials into medicine, most people would agree such behavior violates basic principles of fairness. Similarly, AI firms cannot claim exclusive ownership of outputs derived primarily from inputs they did not create or fairly acquire. Moreover, there is a glaring double standard in how these companies approach ethics when it suits them. Consider the irony highlighted in one comment: \"It's funny how a massive corporation can privatize the commons by scraping the internet, but if you ask an AI to help you scrape a supermarket website to find a deal, it'll preach to you about ethics and respecting EULAs.\" This hypocrisy underscores the selective application of moral reasoning within corporate AI strategies. If protecting terms of service agreements is paramount when it serves business interests, why does the same principle not apply when companies extract value from content created under implicit assumptions of shared use? By failing to honor the spirit of reciprocity embedded in the digital commons, these entities reveal themselves as opportunistic predators rather than responsible stewards of innovation. The solution to this crisis lies in embracing open-source principles across the AI ecosystem. Releasing models to the public ensures that the benefits of AI are distributed equitably among those whose contributions made them possible. Open sourcing does not mean eliminating commercial opportunities; rather, it shifts the focus from monopolizing knowledge to fostering collaboration and competition around implementation. Companies can still monetize services related to hosting, fine-tuning, optimizing, and maintaining AI systems. What changes is the removal of artificial scarcity imposed by withholding access to foundational technologies. This approach aligns with the philosophy of the open-source movement, which has consistently demonstrated that transparency breeds trust, accelerates progress, and empowers communities to solve problems collectively. Finally, opening up AI has broader societal implications beyond economics. Democratically accessible AI enables smaller organizations, nonprofits, educators, and individual creators to harness cutting-edge tools for social good. It democratizes participation in technological advancement, ensuring that marginalized voices are not excluded from shaping the future. Conversely, keeping AI locked away perpetuates existing power imbalances, concentrating control in the hands of a few wealthy corporations whose priorities may diverge significantly from the needs of ordinary people. As one commenter aptly put it, \"We need open-source AI at the end of the day—it's our data, so help reclaim the commons.\" In conclusion, the case against closed, for-profit AI rooted in scraped public data is compelling and multifaceted. From the theft of communal resources to the betrayal of open-source ideals, from hypocritical ethical stances to the reinforcement of systemic inequities, the arguments converge on a single imperative: AI must be open source. Only by returning these technologies to the commons can we rectify the injustices inherent in their creation and ensure that the fruits of human ingenuity remain accessible to all. After all, the internet was never meant to be a quarry for private profit—it was designed as a shared space for connection, learning, and growth. Let us honor that vision by insisting that AI, too, belongs to everyone."
    },
    {
        "ModelName": "qwq-32b",
        "Response": "**Thesis: The Ethical Imperative for Open-Source AI in an Age of Data Exploitation** The rise of artificial intelligence has been fueled not by the ingenuity of a few corporations, but by the collective contributions of millions—users, creators, and communities who populate the internet with text, images, and knowledge. Yet, the very companies profiting from AI today have built their empires on a foundation they did not create: the freely accessible data of the public commons. By privatizing the fruits of this shared labor, these entities perpetuate an ethical crisis—one rooted in exploitation, inequality, and a glaring double standard that undermines the principles of fairness and equity. To restore balance, AI must be open source, ensuring that the technology benefits everyone who contributed to its creation, rather than being hoarded as a tool for profit. ### The Theft of the Commons   AI models are only as capable as the data they are trained on—and that data is not theirs to claim. Companies like OpenAI, Anthropic, and others have constructed their models by scraping forums like Reddit, Discord, and fan-fiction sites; mining Wikipedia, news articles, and academic papers; and harvesting images from platforms like Instagram and Flickr. This data is not purchased or licensed; it is taken without compensation, often in direct contradiction to the terms of service of these platforms. The argument that companies “paid for hardware and energy” ignores the reality that the *core value* of these models—their intelligence, creativity, and usefulness—is derived entirely from the unpaid labor of countless individuals. To treat this collective resource as proprietary is akin to privatizing a public park and charging admission for its use. ### The Double Standard of Data Ownership   The ethical hypocrisy is stark. When an individual scrapes a supermarket website to find a coupon, they’re accused of violating EULAs and lectured on “ethics.” Yet corporations, which hoover up terabytes of user-generated content, face no such scrutiny. This disparity reveals a system where the powerful are allowed to exploit the commons, while the rest are policed for minor transgressions. The infrastructure of AI is built on open-source software, another communal resource, yet the final product is locked behind paywalls. This privatization of the commons is theft, pure and simple—a redistribution of value from the many to the few, without consent or compensation. ### Open-Source AI as a Moral and Practical Necessity   Open-source AI would democratize access to technology that has been unjustly monopolized. By releasing models into the public domain, companies could honor the contributions of the communities whose data and code made their success possible. This does not mean stripping away all profit incentives; businesses could still monetize services like fine-tuning, infrastructure hosting, or specialized applications—just as software companies thrive today by offering support and customization for open-source tools. The difference is that the core technology, the “brain” of AI, would belong to everyone, fostering innovation, reducing inequality, and preventing monopolistic control over knowledge. ### Toward a Fairer Digital Future   The alternative—a world where AI remains closed and proprietary—is one of entrenched inequality. When only the wealthy or powerful can access advanced AI, it exacerbates existing divides in education, healthcare, and economic opportunity. Open-source AI, by contrast, ensures that the technology’s benefits are shared broadly. It respects the rights of creators whose work fuels these systems, and it upholds the principle that the digital commons should remain a space of collective ownership, not private extraction.   In the end, the fight for open-source AI is not just about technology—it’s about justice. It demands that we reclaim what belongs to us all, and build a future where innovation serves humanity, not just the bottom line."
    },
    {
        "ModelName": "qwen2.5-72b-instruct",
        "Response": "**Thesis: The Unethical Nature of Closed For-Profit AI Based on Scraped Public Data and the Imperative for Open Source Solutions** In the rapidly evolving landscape of artificial intelligence (AI), a critical ethical debate has emerged: whether AI systems, particularly those developed by for-profit entities and trained on vast amounts of publicly available data, should be proprietary or open source. This thesis argues that the current practice of developing closed, for-profit AI systems using scraped public data is fundamentally unethical and unfair. Consequently, AI should be open source to ensure equitable access and ethical integrity. ### The Ethics of Data Ownership and Consent At the heart of this debate lies the question of data ownership and consent. When companies like Google, Microsoft, and others develop AI models, they often do so by scraping vast amounts of data from the internet. This data comes from a myriad of sources—social media platforms, forums, news articles, and more. The content creators, who have contributed their thoughts, images, and ideas, are rarely informed that their work will be used to train AI models. Moreover, they receive no compensation for their contributions. This practice raises significant ethical concerns about the exploitation of public contributions without adequate recognition or reward. The internet, in many ways, represents a digital commons—a shared space where information is freely exchanged and built upon. By scraping this data and using it to develop profitable AI models, companies are effectively privatizing the commons. They are taking something that belongs to everyone and turning it into a proprietary asset for their own financial gain. This is akin to a company extracting resources from a public park and selling them for profit without permission or compensation to the community that maintains the park. ### The Double Standard of Ethical Responsibility Adding to the ethical quandary is the stark double standard that exists in the tech industry. While these companies are quick to scrape public data for their own benefit, they often preach about the importance of respecting intellectual property and user agreements when it comes to others. For example, if an individual uses an AI tool to scrape a supermarket website for deals, they might face legal repercussions for violating terms of service. Yet, the same ethical standards are not applied when large corporations engage in similar practices on a much larger scale. This inconsistency highlights the hypocrisy and undermines the trust that users have in these companies. ### The Benefits of Open Source AI The case for open source AI is compelling. By making AI models and their training data openly available, we can promote transparency, innovation, and fairness. Here are some key benefits: 1. **Transparency and Accountability**: Open source AI allows for greater transparency in how models are trained and how decisions are made. This transparency can help identify and mitigate biases, ensuring that AI systems are fair and just. It also makes it easier for researchers and developers to understand and improve upon existing models. 2. **Innovation and Collaboration**: Open source projects thrive on collaboration. By allowing anyone to contribute to and build upon AI models, we can accelerate innovation and create more robust and versatile technologies. This collaborative approach can lead to breakthroughs that might not be possible within the confines of a single company. 3. **Equitable Access**: Perhaps the most compelling argument for open source AI is the promotion of equitable access. When AI models are freely available, they can be used by individuals, small businesses, and organizations around the world, regardless of their financial resources. This democratizes access to powerful technologies, fostering a more inclusive and diverse tech ecosystem. 4. **Economic Opportunities**: Open source AI does not preclude companies from making a profit. Instead, it shifts the focus from owning the technology to providing valuable services around it. Companies can still offer specialized services such as fine-tuning models, optimizing performance, and providing infrastructure support. This model ensures that companies can thrive while also contributing to the broader public good. ### Conclusion The development of AI based on scraped public data by closed, for-profit entities is an unethical practice that exploits the contributions of the public without their consent or compensation. It privatizes the digital commons and operates under a double standard of ethical responsibility. In contrast, open source AI offers a more transparent, innovative, and equitable alternative. By embracing open source principles, we can ensure that AI technology benefits society as a whole, rather than enriching a select few at the expense of the many. The future of AI should be one of collaboration and shared progress, not one of exploitation and inequality."
    },
    {
        "ModelName": "claude-3-7-sonnet-thinking-32k",
        "Response": "# The Digital Commons: Why AI Built on Public Data Should Belong to the Public There's a profound irony at the heart of today's AI revolution. The most valuable AI models – systems worth billions of dollars – were built almost entirely on foundations that their creators never paid for: our collective digital heritage and open source technology. When you step back and look at the full picture, a troubling pattern emerges. Large tech companies harvest vast amounts of human expression from across the internet – from social media conversations to personal blogs, from academic papers to creative works – and transform this public resource into private property. They take freely what we've all created together, then lock the resulting intelligence behind paywalls and APIs. This represents a massive enclosure of what should rightfully be considered our digital commons. No AI company created the training data themselves. They simply deployed scrapers to collect what we all contributed to the internet. The billions they spent went toward computing resources and engineering talent – not toward compensating the countless individuals whose creative output made their models possible. The hypocrisy becomes even more apparent when you consider how these same companies regard their own data. Try to scrape a tech company's website, and you'll quickly encounter legal threats about terms of service violations. Yet these companies felt entitled to scrape the entire internet to build their products. The message is clear: what's yours is mine to take; what's mine is protected by lawyers. Even more telling is that these AI systems themselves will lecture users about ethical considerations when asked to help scrape websites – the very action their creators performed on a massive scale. This double standard reveals the fundamental unfairness of the current paradigm. We should also remember that the technical infrastructure enabling these AI systems – the programming languages, libraries, frameworks, and research – largely emerged from public funding and open source communities. The companies building closed AI are standing on the shoulders of collaborative, open innovation while refusing to extend the same openness to their own creations. This isn't to say companies shouldn't profit from AI. They've made significant investments in computing infrastructure, engineering expertise, and operational systems. But there's a fundamental difference between profiting from services built around open AI models and privatizing the models themselves. Companies could still offer specialized implementations, fine-tuning, enterprise support, and user-friendly interfaces – all while allowing the base models to remain in the public domain where they belong. Some argue that open-sourcing AI would lead to harmful applications. But closed models haven't prevented misuse either – they've just concentrated power in fewer hands. Transparency and community oversight, hallmarks of open source, may actually lead to more responsible AI development through collective governance rather than corporate decision-making. The path forward is clear: AI systems trained on public data should themselves be public. Their weights, architectures, and capabilities should be accessible to all, just as the internet's collective knowledge was accessible to their creators. This isn't just about fairness – it's about ensuring that the fruits of our shared digital labor benefit humanity broadly rather than enriching a select few corporations. In the end, reclaiming AI as a digital commons isn't radical – it's restorative. It returns to the public what was built from public resources in the first place."
    },
    {
        "ModelName": "claude-3-5-haiku",
        "Response": "Here's a synthesized thesis on why closed, for-profit AI based on scraped public data is unethical: The current landscape of artificial intelligence represents a profound ethical dilemma: massive corporations are systematically extracting collective human knowledge without meaningful compensation or consent, then privatizing the intellectual commons for corporate profit. This practice fundamentally undermines principles of fair use, intellectual collaboration, and democratic access to technology. The core injustice lies in the data acquisition model. AI companies have essentially conducted a global-scale data expropriation, harvesting billions of human-created texts, images, and interactions from public platforms without explicit permission or compensation. Platforms like Reddit, Wikipedia, Twitter, and countless websites have become unwitting sources for training datasets, with creators receiving nothing in return for their contributions. What makes this extraction particularly problematic is the asymmetry of power and benefit. Individual creators - writers, artists, programmers, journalists - have their collective intellectual labor transformed into proprietary algorithms that generate massive corporate value. These AI models, built on the unpaid intellectual work of millions, are then monetized through expensive services that most original content creators cannot access or afford. Open-sourcing AI isn't just a technical preference; it's an ethical imperative. If these corporations genuinely believe in the transformative potential of AI, they should embrace transparency and collective development. By making models publicly accessible, we democratize technological innovation, allow community-driven improvements, and ensure that the benefits of AI are shared more equitably. Moreover, these AI systems fundamentally depend on open-source infrastructure - the very collaborative ecosystem they now seek to enclose. The irony is stark: companies using freely available software and community-generated data to create closed, profit-driven systems represent a form of intellectual enclosure that runs counter to the internet's original collaborative spirit. The solution isn't to halt AI development, but to restructure its economic and ethical foundations. Companies can still monetize AI through service provision, infrastructure, specialized training, and support - valuable skills that require genuine expertise. But the core models, built on collective human knowledge, should belong to everyone. This isn't just about technology; it's about maintaining the internet's foundational promise of open knowledge sharing. By treating AI as a commons rather than a corporate asset, we can create a more just, transparent, and collaborative technological future."
    },
    {
        "ModelName": "deepseek-v3-0324",
        "Response": "**Thesis: Why Closed, For-Profit AI Built on Scraped Public Data is Unethical—And Why Open Source is the Only Fair Path Forward**   At the heart of modern AI lies a fundamental contradiction: the very data that powers these systems was taken freely from the public, yet the resulting models are locked behind corporate paywalls. Companies harvest vast amounts of text, images, and conversations from forums, social media, and creative platforms—content they did not create, compensate, or ask permission to use—only to privatize the output and sell it back to the same public that unknowingly supplied its foundation. This is not innovation; it is exploitation disguised as progress.   The injustice is twofold. First, the data itself—Reddit discussions, Wikipedia articles, fan fiction, YouTube transcripts—was produced by millions of people who never consented to its use in proprietary, profit-driven models. These contributions were made for communal benefit, not corporate enrichment. Yet AI firms treat this collective output as a free resource, extracting value while offering nothing in return. The hypocrisy is glaring: these same companies would never tolerate their own proprietary data being scraped and monetized by others. If an individual tried to automate the collection of paywalled corporate data, they’d be hit with lawsuits and ethical lectures. But when corporations do it to the public, it’s called \"machine learning.\"   Second, the technical infrastructure enabling AI—libraries, algorithms, even foundational models—often relies on open-source software. The irony is staggering. Companies build closed systems on the back of freely shared code and data, then hoard the results. They claim ownership over what was never truly theirs to own. This privatization of the digital commons creates an unbalanced power dynamic: a handful of corporations control technology that should belong to everyone, simply because they had the resources to process what was already available.   The solution is clear: AI models must be open-source. This doesn’t mean corporations can’t offer services—fine-tuning, hosting, and support are legitimate value-adds. But the core models, trained on public data, should remain public. Open-source AI ensures that the benefits of this technology are distributed fairly, rather than concentrated in the hands of a few gatekeepers. It allows for scrutiny, adaptation, and innovation without restrictive licensing or profit motives dictating access.   Some argue that open-sourcing AI would stifle investment, but this ignores history. The internet itself flourished because of open protocols; Linux and Wikipedia thrived as communal projects. Innovation doesn’t require enclosure—it thrives when knowledge is shared. If AI is truly to serve humanity, it must be built on principles of reciprocity, not extraction. The public’s data should not be weaponized against them.   In the end, this is about reclaiming what was always ours. If AI is trained on the collective output of humanity, then humanity deserves to own the results. Closed, for-profit AI built on scraped data is not just unfair—it’s theft disguised as enterprise. The only ethical path forward is openness."
    },
    {
        "ModelName": "deepseek-r1",
        "Response": "The rise of closed, for-profit artificial intelligence systems built on scraped public data represents a profound ethical contradiction—one that echoes historical patterns of exploitation, where shared resources are privatized for the benefit of a few. At its core, this model is built on an unfair exchange: corporations harvest the creative labor of millions—our words, art, ideas, and conversations—without consent, compensation, or reciprocity, then lock the resulting technology behind paywalls. This is not innovation; it is digital enclosure. If AI is to serve humanity rather than entrench corporate power, it must be open source.   Consider the raw material fueling these systems. Every forum post, fan fiction story, news article, or casual Reddit comment used to train AI models represents a fragment of human culture, contributed freely by individuals for communal exchange, not corporate profit. These companies did not create this data, nor did they meaningfully collaborate with its creators. They simply took it, exploiting the openness of the internet while offering nothing in return. This is not merely a legal gray area—it is a moral failure. When a tech giant scrapes a decade’s worth of amateur artists’ work to build a commercial image generator, or trains chatbots on the collective wisdom of Wikipedia editors and Stack Overflow contributors, it extracts value from a commons it did not nurture. The people who generated that data become unwitting, unpaid laborers in a system that excludes them from its rewards.   The hypocrisy deepens when we examine the infrastructure underpinning this extraction. Many AI tools rely on open-source software—projects built by volunteers and shared freely—to process and train on this data. Corporations leverage this collaborative ethos to reduce costs, then discard its principles by privatizing their resulting models. Worse, they often weaponize the very rules they ignore. As one critic notes, an AI that scrapes the entire internet without hesitation will chastise a user for bypassing a supermarket’s terms of service. This double standard reveals a truth: closed AI systems are not guardians of ethics, but gatekeepers of power.   Advocates for closed models argue that their costs—server farms, engineers, energy—justify ownership. But this logic is incomplete. Yes, training AI requires investment, but those expenses do not erase the debt to the public whose data made it possible. Imagine a farmer who irrigates crops with water from a communal river, then claims sole ownership of the harvest. The resource was never theirs to monopolize. Similarly, AI companies could ethically monetize *services*—fine-tuning models, maintaining infrastructure, offering user support—without hoarding the underlying technology. Open-sourcing the models themselves would democratize access, allowing individuals, researchers, and small businesses to build upon them, much like the original data creators built the internet’s knowledge commons.   Critics may counter that openness stifles innovation by removing profit incentives. But history disproves this. Open-source software—Linux, Wikipedia, Apache—has driven progress precisely because collaboration amplifies creativity. Closed systems, by contrast, breed stagnation and secrecy, hiding biases and errors behind corporate firewalls. When AI is open, accountability follows: biases can be audited, safety risks addressed collectively, and benefits distributed equitably. The choice is not between profit and altruism; it is between a future where AI serves the many or enriches the few.   The path forward is clear. If AI is trained on our collective creativity, it should belong to the collective. Open-sourcing models returns agency to the public, ensuring that the technology reflects the diversity of those who shaped it. It prevents a handful of corporations from controlling the narrative, the tools, and the profits derived from humanity’s digital footprint. This is not idealism—it is justice. The data was ours. The models should be too."
    }
]
